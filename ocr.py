# -*- coding: utf-8 -*-
"""OCR.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1HnTtzjo1cC6cXXwcoA18QD_xp6n_1p_z
"""

from googletrans import Translator

!pip install googletrans==4.0.0-rc1

pip install opencv-python

pip install tesseract

pip install pytesseract

import cv2
from PIL import Image
import pytesseract

from PIL import Image

im_file = "/content/Rental-Agreement-Format.jpg"

im = Image.open(im_file)
im.save("/content/test.png")
im.show()

import cv2
from matplotlib import pyplot as plt
image_file = "/content/test.png"
img = cv2.imread(image_file)

def display(im_path):
    dpi = 80
    im_data = plt.imread(im_path)

    height, width  = im_data.shape[:2]

    # What size does the figure need to be in inches to fit the image?
    figsize = width / float(dpi), height / float(dpi)

    # Create a figure of the right size with one axes that takes up the full figure
    fig = plt.figure(figsize=figsize)
    ax = fig.add_axes([0, 0, 1, 1])

    # Hide spines, ticks, etc.
    ax.axis('off')

    # Display the image.
    ax.imshow(im_data, cmap='gray')

    plt.show()

display(image_file)

""" Inverted Images"""

inverted_image = cv2.bitwise_not(img)
cv2.imwrite("/content/inverted.png", inverted_image)

display("/content/inverted.png")

####### Binarization

def grayscale(image):
    return cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)

gray_image = grayscale(img)
cv2.imwrite("/content/gray.png", gray_image)

display("/content/gray.png")

thresh, im_bw = cv2.threshold(gray_image, 200, 230, cv2.THRESH_BINARY)
cv2.imwrite("/content/bw_image.png", im_bw)

display("/content/bw_image.png")

"""Noise Removal"""

def noise_removal2(image):
    import numpy as np
    kernel = np.ones((1, 1), np.uint8)
    image = cv2.dilate(image, kernel, iterations=1)
    kernel = np.ones((1, 1), np.uint8)
    image = cv2.erode(image, kernel, iterations=1)
    image = cv2.morphologyEx(image, cv2.MORPH_CLOSE, kernel)
    image = cv2.medianBlur(image, 3)
    return (image)

import cv2
import numpy as np

def noise_removal(image):
    if len(image.shape) > 2:
        gray_image = cv2.cvtColor(image, cv2.COLOR_BGR2GRAY)
    else:
        gray_image = image

    _, binary_mask = cv2.threshold(gray_image, 200, 255, cv2.THRESH_BINARY_INV)

    kernel = np.ones((3, 3), np.uint8)
    opened_mask = cv2.morphologyEx(binary_mask, cv2.MORPH_OPEN, kernel, iterations=2)

    closed_mask = cv2.morphologyEx(opened_mask, cv2.MORPH_CLOSE, kernel, iterations=2)

    cleaned_background = cv2.bitwise_and(gray_image, gray_image, mask=closed_mask)

    cleaned_image = cv2.bitwise_and(gray_image, gray_image, mask=~closed_mask)

    final_image = cv2.add(cleaned_background, cleaned_image)

    return final_image

no_noise = noise_removal2(im_bw)
cv2.imwrite("/content/no_noise.png", no_noise)

no_noise = noise_removal(im_bw)
cv2.imwrite("/content/no_noise.png", no_noise)

display("/content/no_noise.png")

"""Dilation and Erosion"""

def thin_font(image):
    import numpy as np
    image = cv2.bitwise_not(image)
    kernel = np.ones((2,2),np.uint8)
    image = cv2.erode(image, kernel, iterations=1)
    image = cv2.bitwise_not(image)
    return (image)

eroded_image = thin_font(no_noise)
cv2.imwrite("/content/eroded_image.jpg", eroded_image)

display("/content/eroded_image.jpg")

def thick_font(image):
    import numpy as np
    image = cv2.bitwise_not(image)
    kernel = np.ones((2,2),np.uint8)
    image = cv2.dilate(image, kernel, iterations=1)
    image = cv2.bitwise_not(image)
    return (image)

dilated_image = thick_font(no_noise)
cv2.imwrite("/content/dilated_image.jpg", dilated_image)

display("/content/dilated_image.jpg")

""" Rotation / Deskewing"""

new = cv2.imread("/content/skewed image.png")
display("/content/skewed image.png")

import numpy as np

def getSkewAngle(cvImage) -> float:
    # Prep image, copy, convert to gray scale, blur, and threshold
    newImage = cvImage.copy()
    gray = cv2.cvtColor(newImage, cv2.COLOR_BGR2GRAY)
    blur = cv2.GaussianBlur(gray, (9, 9), 0)
    thresh = cv2.threshold(blur, 0, 255, cv2.THRESH_BINARY_INV + cv2.THRESH_OTSU)[1]

    # Apply dilate to merge text into meaningful lines/paragraphs.
    # Use larger kernel on X axis to merge characters into single line, cancelling out any spaces.
    # But use smaller kernel on Y axis to separate between different blocks of text
    kernel = cv2.getStructuringElement(cv2.MORPH_RECT, (30, 5))
    dilate = cv2.dilate(thresh, kernel, iterations=2)

    # Find all contours
    contours, hierarchy = cv2.findContours(dilate, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    contours = sorted(contours, key = cv2.contourArea, reverse = True)
    for c in contours:
        rect = cv2.boundingRect(c)
        x,y,w,h = rect
        cv2.rectangle(newImage,(x,y),(x+w,y+h),(0,255,0),2)

    # Find largest contour and surround in min area box
    largestContour = contours[0]
    print (len(contours))
    minAreaRect = cv2.minAreaRect(largestContour)
    cv2.imwrite("/content/boxes.jpg", newImage)
    # Determine the angle. Convert it to the value that was originally used to obtain skewed image
    angle = minAreaRect[-1]
    if angle < -45:
        angle = 90 + angle
    return -1.0 * angle
# Rotate the image around its center
def rotateImage(cvImage, angle: float):
    newImage = cvImage.copy()
    (h, w) = newImage.shape[:2]
    center = (w // 2, h // 2)
    M = cv2.getRotationMatrix2D(center, angle, 1.0)
    newImage = cv2.warpAffine(newImage, M, (w, h), flags=cv2.INTER_CUBIC, borderMode=cv2.BORDER_REPLICATE)
    return newImage

# Deskew image
def deskew(cvImage):
    angle = getSkewAngle(cvImage)
    return rotateImage(cvImage, -1.0 * angle)

fixed = deskew(new)
cv2.imwrite("/content/rotated_fixed.jpg", fixed)

display("/content/rotated_fixed.jpg")

"""Removing Borders"""

display("/content/no_noise.png")

def remove_borders(image):
    contours, heiarchy = cv2.findContours(image, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_SIMPLE)
    cntsSorted = sorted(contours, key=lambda x:cv2.contourArea(x))
    cnt = cntsSorted[-1]
    x, y, w, h = cv2.boundingRect(cnt)
    crop = image[y:y+h, x:x+w]
    return (crop)

no_borders = remove_borders(no_noise)
cv2.imwrite("/content/no_borders.jpg", no_borders)
display('/content/no_borders.jpg')

no_borders = remove_borders(no_noise)
cv2.imwrite("/content/no_borders.jpg", no_borders)
display('/content/no_borders.jpg')

"""ADDING BORDER"""

color = [255,255,255]
top , bottom , left , right = [150]*4

image_with_border = cv2.copyMakeBorder(no_borders,top , bottom , left , right ,cv2.BORDER_CONSTANT , value = color)
cv2.imwrite("/content/image_with_border.jpg" ,image_with_border )
display("/content/image_with_border.jpg")

# pip install pytesseract

# import pytesseract
# from PIL import Image

# img_file = "/content/download.png"
# no_noise = "/content/no_noise.jpg"

# img = Image.open(no_noise)
# display(img)



!sudo apt-get install tesseract-ocr

!pip install pytesseract

import pytesseract
from pytesseract import Output
pytesseract.pytesseract.tesseract_cmd = '/usr/bin/tesseract'

from PIL import Image
import pytesseract
from PIL import Image


img_file = "/content/download.png"
no_noise = "/content/image_with_border.jpg"

ocr_result = pytesseract.image_to_string(no_noise)

print(ocr_result)

ocr_result = pytesseract.image_to_string("/content/Rental-Agreement-Format.jpg")

print(ocr_result)

import torch
from transformers import BertTokenizer, BertForSequenceClassification, Trainer, TrainingArguments, AutoTokenizer, AutoModel, BartForConditionalGeneration, BertLMHeadModel, pipeline

tokenizer = AutoTokenizer.from_pretrained("nlpaueb/legal-bert-base-uncased")

model = BertLMHeadModel.from_pretrained("nlpaueb/legal-bert-base-uncased")

def generate_text(input_text, max_length=500):
    inputs = tokenizer.encode(input_text, return_tensors="pt")
    outputs = model.generate(inputs, max_length=max_length, do_sample=True, top_k=50, top_p=0.95, num_return_sequences=1)
    generated_text = tokenizer.decode(outputs[0], skip_special_tokens=True)

    return generated_text

summarizer = pipeline("summarization", model="facebook/bart-large-cnn")

ARTICLE=input()
print(summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False))
Bert_out = summarizer(ARTICLE, max_length=130, min_length=30, do_sample=False)

translator = Translator()

english_text = str(Bert_out[0]).strip('{}')

translated = translator.translate(english_text, src='en', dest='hi')
print("Hindi Translation: ",translated.text)

translated_marathi = translator.translate(english_text, src='en', dest='mr')
print("Marathi Translation: ", translated_marathi.text)

translated_bengali = translator.translate(english_text, src='en', dest='bn')
print("Bengali Translation: ", translated_bengali.text)

